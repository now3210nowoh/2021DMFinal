{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "103a4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, glob, time, copy, random, zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c05b6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join,splitext\n",
    "datapath = 'Stage_2\\dataPublicComplete_s2\\dataPublicComplete'\n",
    "txt_fnames = [splitext(f)[0] for f in listdir(datapath) if isfile(join(datapath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e45dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_list = open('Keywords/02crop.list.csv', \"r\",encoding='UTF-8-sig')\n",
    "crop = crop_list.read()\n",
    "crop_line_sep = crop.splitlines()\n",
    "\n",
    "pest_list = open('Keywords/02pest.list.csv', \"r\",encoding='UTF-8-sig')\n",
    "pest = pest_list.read()\n",
    "pest_line_sep = pest.splitlines()\n",
    "\n",
    "chem_list = open('Keywords/02chem.list.csv', \"r\",encoding='UTF-8-sig')\n",
    "chem = chem_list.read()\n",
    "chem_line_sep = chem.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fac3e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Renewrr\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.703 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "vector_dict = {}\n",
    "for idx,line in enumerate(chain(crop_line_sep,pest_line_sep,chem_line_sep)):\n",
    "    l = line.split(',')\n",
    "    for word in l:\n",
    "        if(word == ''):continue\n",
    "        jieba.add_word(word)\n",
    "        vector_dict[word] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b739aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = {}\n",
    "for fname in txt_fnames:\n",
    "    txt = open(datapath+'/'+fname+'.txt', \"r\",encoding=\"utf-8\")\n",
    "    content = txt.read()\n",
    "    seg_list = jieba.cut(content, cut_all=True)\n",
    "    vectors[fname] = [0]*764\n",
    "    for seg in seg_list:\n",
    "        if(seg in vector_dict):\n",
    "            vectors[fname][vector_dict[seg]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef79f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2*764, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "05417d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork()\n",
    "net.load_state_dict(torch.load('best_checkpoint_last_b4000.pth'))\n",
    "net.eval()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e303af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "with torch.no_grad():\n",
    "    for fname1 in txt_fnames:\n",
    "        for fname2 in txt_fnames:\n",
    "            if(fname1 == fname2):continue\n",
    "            else:\n",
    "                comb_vec = torch.tensor(vectors[fname1]+vectors[fname2])\n",
    "                comb_vec = comb_vec.type(torch.FloatTensor).to(device)\n",
    "                lbl = net(comb_vec)\n",
    "                out.append([(fname1,fname2),lbl.cpu()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f3667d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "better = []\n",
    "for o in out:\n",
    "    if(abs(o[1][0]) < 0.0001):\n",
    "        better.append(o[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6b17544b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640\n"
     ]
    }
   ],
   "source": [
    "print(len(better))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e10fc85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1032', '1036'), tensor([-0.0021, -0.0154])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('1001', '1296'), tensor([-0.0058, -0.0151])],\n",
       " [('1001', '1299'), tensor([-0.0072, -0.0141])],\n",
       " [('1001', '13'), tensor([-0.0040, -0.0115])],\n",
       " [('1001', '130'), tensor([-0.0022, -0.0154])],\n",
       " [('1001', '1303'), tensor([-0.0023, -0.0164])],\n",
       " [('1001', '1306'), tensor([-0.0023, -0.0164])],\n",
       " [('1001', '1307'), tensor([-0.0023, -0.0164])],\n",
       " [('1001', '1313'), tensor([-0.0023, -0.0164])],\n",
       " [('1001', '1316'), tensor([-0.0072, -0.0141])],\n",
       " [('1001', '1317'), tensor([-0.0056, -0.0142])],\n",
       " [('1001', '1318'), tensor([-0.0065, -0.0150])],\n",
       " [('1001', '132'), tensor([-0.0056, -0.0167])],\n",
       " [('1001', '1325'), tensor([-0.0045, -0.0152])],\n",
       " [('1001', '1328'), tensor([-0.0040, -0.0178])],\n",
       " [('1001', '1330'), tensor([-0.0012, -0.0147])],\n",
       " [('1001', '1336'), tensor([-0.0047, -0.0130])],\n",
       " [('1001', '1338'), tensor([-0.0043, -0.0139])],\n",
       " [('1001', '134'), tensor([-0.0065, -0.0067])],\n",
       " [('1001', '1344'), tensor([-0.0062, -0.0170])],\n",
       " [('1001', '1345'), tensor([-0.0057, -0.0159])],\n",
       " [('1001', '1346'), tensor([-0.0043, -0.0139])],\n",
       " [('1001', '1349'), tensor([-0.0050, -0.0167])],\n",
       " [('1001', '1351'), tensor([-0.0064, -0.0164])],\n",
       " [('1001', '1353'), tensor([-0.0040, -0.0147])],\n",
       " [('1001', '1360'), tensor([-0.0023, -0.0167])],\n",
       " [('1001', '1368'), tensor([-0.0055, -0.0109])],\n",
       " [('1001', '137'), tensor([-0.0047, -0.0182])],\n",
       " [('1001', '1371'), tensor([-0.0047, -0.0167])],\n",
       " [('1001', '1376'), tensor([-0.0060, -0.0135])],\n",
       " [('1001', '1380'), tensor([-0.0037, -0.0166])],\n",
       " [('1001', '1383'), tensor([-0.0026, -0.0144])],\n",
       " [('1001', '1384'), tensor([-0.0044, -0.0174])],\n",
       " [('1001', '1385'), tensor([-0.0010, -0.0160])],\n",
       " [('1001', '1387'), tensor([-0.0051, -0.0150])],\n",
       " [('1001', '1388'), tensor([-0.0028, -0.0123])],\n",
       " [('1001', '1389'), tensor([-0.0009, -0.0145])],\n",
       " [('1001', '1393'), tensor([-0.0030, -0.0184])],\n",
       " [('1001', '1398'), tensor([-0.0003, -0.0137])],\n",
       " [('1001', '1399'), tensor([-0.0008, -0.0158])],\n",
       " [('1001', '1400'), tensor([-0.0033, -0.0134])],\n",
       " [('1001', '143'), tensor([-0.0043, -0.0110])],\n",
       " [('1001', '145'), tensor([-0.0036, -0.0202])],\n",
       " [('1001', '148'), tensor([-0.0037, -0.0166])],\n",
       " [('1001', '153'), tensor([-0.0047, -0.0156])],\n",
       " [('1001', '159'), tensor([-0.0033, -0.0182])],\n",
       " [('1001', '160'), tensor([-0.0053, -0.0122])],\n",
       " [('1001', '161'), tensor([-0.0019, -0.0165])],\n",
       " [('1001', '162'), tensor([-0.0028, -0.0133])],\n",
       " [('1001', '164'), tensor([-0.0032, -0.0128])],\n",
       " [('1001', '165'), tensor([-0.0049, -0.0194])],\n",
       " [('1001', '168'), tensor([-0.0046, -0.0103])],\n",
       " [('1001', '172'), tensor([-0.0031, -0.0169])],\n",
       " [('1001', '175'), tensor([-0.0035, -0.0183])],\n",
       " [('1001', '177'), tensor([-0.0036, -0.0162])],\n",
       " [('1001', '187'), tensor([-0.0040, -0.0168])],\n",
       " [('1001', '19'), tensor([-2.2207e-06, -1.7183e-02])],\n",
       " [('1001', '190'), tensor([-0.0013, -0.0119])],\n",
       " [('1001', '192'), tensor([ 0.0011, -0.0161])],\n",
       " [('1001', '193'), tensor([-0.0036, -0.0154])],\n",
       " [('1001', '195'), tensor([-0.0031, -0.0173])],\n",
       " [('1001', '198'), tensor([-0.0030, -0.0146])],\n",
       " [('1001', '20'), tensor([-0.0013, -0.0217])],\n",
       " [('1001', '200'), tensor([-0.0005, -0.0160])],\n",
       " [('1001', '202'), tensor([-0.0001, -0.0116])],\n",
       " [('1001', '206'), tensor([-0.0010, -0.0140])],\n",
       " [('1001', '213'), tensor([-0.0008, -0.0143])],\n",
       " [('1001', '214'), tensor([-0.0011, -0.0168])],\n",
       " [('1001', '216'), tensor([-0.0010, -0.0140])],\n",
       " [('1001', '229'), tensor([-0.0005, -0.0144])],\n",
       " [('1001', '233'), tensor([-0.0029, -0.0140])],\n",
       " [('1001', '234'), tensor([-0.0004, -0.0064])],\n",
       " [('1001', '24'), tensor([-0.0024, -0.0172])],\n",
       " [('1001', '244'), tensor([-0.0044, -0.0133])],\n",
       " [('1001', '245'), tensor([-0.0026, -0.0145])],\n",
       " [('1001', '247'), tensor([-0.0022, -0.0129])],\n",
       " [('1001', '249'), tensor([-0.0044, -0.0122])],\n",
       " [('1001', '250'), tensor([-0.0023, -0.0176])],\n",
       " [('1001', '254'), tensor([-0.0006, -0.0147])],\n",
       " [('1001', '257'), tensor([-0.0017, -0.0099])],\n",
       " [('1001', '264'), tensor([-0.0042, -0.0184])],\n",
       " [('1001', '265'), tensor([-0.0053, -0.0099])],\n",
       " [('1001', '269'), tensor([-0.0033, -0.0185])],\n",
       " [('1001', '270'), tensor([-0.0024, -0.0189])],\n",
       " [('1001', '272'), tensor([ 0.0021, -0.0097])],\n",
       " [('1001', '277'), tensor([-0.0033, -0.0141])],\n",
       " [('1001', '28'), tensor([-0.0004, -0.0152])],\n",
       " [('1001', '281'), tensor([-0.0035, -0.0160])],\n",
       " [('1001', '287'), tensor([-0.0028, -0.0164])],\n",
       " [('1001', '288'), tensor([ 0.0003, -0.0170])],\n",
       " [('1001', '290'), tensor([-0.0024, -0.0125])],\n",
       " [('1001', '293'), tensor([ 0.0004, -0.0179])],\n",
       " [('1001', '294'), tensor([ 0.0009, -0.0193])],\n",
       " [('1001', '30'), tensor([-0.0028, -0.0160])],\n",
       " [('1001', '304'), tensor([ 0.0010, -0.0169])],\n",
       " [('1001', '309'), tensor([-0.0022, -0.0128])],\n",
       " [('1001', '31'), tensor([-0.0041, -0.0162])],\n",
       " [('1001', '312'), tensor([-0.0032, -0.0134])],\n",
       " [('1001', '315'), tensor([-0.0021, -0.0200])],\n",
       " [('1001', '324'), tensor([-0.0051, -0.0120])],\n",
       " [('1001', '331'), tensor([-0.0024, -0.0169])]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for o in out:\n",
    "    if(o[0] == ('1032','1036')):\n",
    "        print(o)\n",
    "out[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f69b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('val.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow([\"Test\"]+[\"Reference\"])\n",
    "    for row in better:  \n",
    "        spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8374cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
